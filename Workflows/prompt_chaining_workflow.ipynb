{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c875270f",
   "metadata": {},
   "source": [
    "### Prompt Chaining Workflow using LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcafc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the LLM Model using Ollama (Using the gpt oss 120b cloud model)\n",
    "llm_model = ChatOllama(model='gpt-oss:20b-cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "921ae87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a state\n",
    "class BlogState(TypedDict):\n",
    "    title: str\n",
    "    outline: str\n",
    "    content: str\n",
    "    blog_score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00876a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state: BlogState) -> BlogState:\n",
    "    \"\"\"\n",
    "    Function to extract title from the state,\n",
    "    Call the LLM to generate an outline for the title,\n",
    "    Update the state with the generated outline\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch the title\n",
    "    title = state['title']\n",
    "\n",
    "    # Prompt for generating outline based on title\n",
    "    prompt = f'Create a detailed outline for a blog based on the given title: {title}'\n",
    "\n",
    "    # Calling the llm to generate outline\n",
    "    outline = llm_model.invoke(prompt).content\n",
    "\n",
    "    # Updating the state with the generated outline\n",
    "    state['outline'] = outline\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43383e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blog(state: BlogState) -> BlogState:\n",
    "    \"\"\"\n",
    "    Function to extract title and outline from the state,\n",
    "    Call the LLM to generate a content based on the title and outline,\n",
    "    Update the state with the generated content\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch the title and outline\n",
    "    title = state['title']\n",
    "    outline = state['outline']\n",
    "\n",
    "    # Prompt for generating outline based on title\n",
    "    prompt = f'Generate detailed content for a blog with the title: {title}, and outline: {outline}'\n",
    "\n",
    "    # Calling the llm to generate outline\n",
    "    content = llm_model.invoke(prompt).content\n",
    "\n",
    "    # Updating the state with the generated outline\n",
    "    state['content'] = content\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb9edc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_blog(state: BlogState) -> BlogState:\n",
    "    \"\"\"\n",
    "    Function to extract content and outline from the state,\n",
    "    Call the LLM to generate a score based on the content and outline,\n",
    "    Update the state with the generated evaluation score\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch the title and outline\n",
    "    outline = state['outline']\n",
    "    content = state['content']\n",
    "\n",
    "    # Prompt for generating outline based on title\n",
    "    prompt = f'Based on the provided blog outline and blog content, evaluate and rate my blog on a scale of 1-10, {outline}, {content}'\n",
    "\n",
    "    # Calling the llm to generate outline\n",
    "    blog_score = llm_model.invoke(prompt).content\n",
    "\n",
    "    # Updating the state with the generated outline\n",
    "    state['blog_score'] = blog_score\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c829fa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000020221748F50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a graph\n",
    "graph = StateGraph(BlogState)\n",
    "\n",
    "# Adding nodes to the graph\n",
    "graph.add_node('create_outline', create_outline)\n",
    "graph.add_node('create_blog', create_blog)\n",
    "graph.add_node('evaluate_blog', evaluate_blog)\n",
    "\n",
    "# Adding edges to the graph\n",
    "graph.add_edge(START, 'create_outline')\n",
    "graph.add_edge('create_outline', 'create_blog')\n",
    "graph.add_edge('create_blog', 'evaluate_blog')\n",
    "graph.add_edge('evaluate_blog', END)\n",
    "\n",
    "# Compiling the graph\n",
    "workflow = graph.compile()\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2de4f0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Generative AI',\n",
       " 'outline': '## Blog Outline  \\n**Title:** *Generative AI – From Groundbreaking Theory to Everyday Impact*\\n\\n| Section | Sub‑sections | Key Talking Points | Suggested Word Count |\\n|---------|--------------|--------------------|----------------------|\\n| 1. Introduction |  | • Hook: “What if your computer could write a novel, design a car, or even compose music? That’s Generative AI.” <br>• Define the scope of the blog: explaining what generative AI is, its evolution, applications, challenges, and the road ahead. <br>• Preview of sections. | 150–200 |\\n| 2. From Concept to Reality | 2.1 Early Foundations <br>2.2 Birth of Generative Models <br>2.3 The Rise of Deep Learning | • Informal “ATGPT” analogy: earliest statistical models → first neural nets → modern deep learning <br>• 1990s: Markov chains, n‑gram models. <br>• 2000‑2010: Autoencoders, Restricted Boltzmann Machines. <br>• 2014‑present: Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs); 2018‑2022: Transformer‑based language models (GPT‑3, GPT‑4). | 500–600 |\\n| 3. How Generative AI Works | 3.1 Core Technologies <br>3.1.1 GANs (adversarial training) <br>3.1.2 VAEs (probabilistic sampling) <br>3.1.3 Transformers (attention & autoregression) <br>3.2 Training Data & Computational Demands | • Diagram of GAN: generator vs. discriminator <br>• Explain latent space, reparameterization trick <br>• Show how Transformers predict next token and generate coherent text <br>• Highlight GPU/TPU spin‑up, cloud APIs, data‑ownership issues | 700–800 |\\n| 4. Applications – The “Why It Matters” Section | 4.1 Creative Arts & Design <br>4.1.1 Music & Visual Arts <br>4.1.2 Film & Animation <br>4.2 Business & Productivity <br>4.2.1 Content Creation & Copywriting <br>4.2.2 Code Generation & Automation <br>4.3 Healthcare & Science <br>4.3.1 Molecular Design <br>4.3.2 Drug Discovery <br>4.4 Education & Accessibility <br>4.5 Social Media & Marketing | • Use bullet‑style real‑world examples: OpenAI’s DALL‑E, Jukebox; GitHub Copilot, LangChain <br>• Cite key metrics (e.g., time saved, accuracy improvements) <br>• Discuss augmentation vs. replacement on the workforce | 1200–1400 |\\n| 5. Benefits & Advantages | 5.1 Speed & Scale <br>5.2 Lower Cost <br>5.3 Democratization of Expertise <br>5.4 Personalization & Customization | • Quantify: “A single GPT‑4 model can draft 50% of the copy in a 100‑page document in an hour.” <br>• Illustrate democratization: small teams now producing on‑par marketing copy vs. agencies. | 400–500 |\\n| 6. Risks, Ethics & Social Implications | 6.1 Bias & Fairness <br>6.2 Copyright & Plagiarism <br>6.3 Deepfakes & Misinformation <br>6.4 Environmental Impact (energy consumption) <br>6.5 Accountability & Governance | • Real case studies: Picasso style AI bias, AI‑generated fake news <br>• Highlight regulatory responses (EU AI Act, US Standards). | 900–1000 |\\n| 7. The Business Adoption Playbook | 7.1 Identifying Use‑Cases <br>7.2 PoC to Production <br>7.3 Choosing the Right Model (in‑house vs. API) <br>7.4 Integration with Existing Workflows <br>7.5 Upskilling & Workforce Considerations | • Use “Value‑Chain” diagram; Example: Content marketing team + GPT‑4. <br>• Step‑by‑step guide for building a pilot (define problem → get data → fine‑tune). | 800–950 |\\n| 8. Emerging Trends & the Road Ahead | 8.1 Multi‑Modal Models (Text+Image+Audio) <br>8.2 Federated & Edge Generative AI <br>8.3 Self‑Training & Continual Learning <br>8.4 AI‑Generated Hardware & Architectures <br>8.5 Human‑In‑The‑Loop (HITL) frameworks | • Mention Claude 3.5, Meta’s Llama‑3, Google Gemini <br>• Speculate on breakthroughs: “Neural‑rendered graphics in VR” <br>• Future of governance: AI‑generated policy documents. | 600–700 |\\n| 9. Resources & Next Steps | 9.1 Key Reading (papers & books) <br>9.2 Open‑Source Tools & Libraries (Hugging Face, Diffusers) <br>9.3 Learning Paths (Coursera, Fast.ai) <br>9.4 Communities & Conferences | • Provide curated links. <br>• Recommendation for practitioners: “Start with GPT‑4 via OpenAI API, then build your own fine‑tuned model.” | 300–400 |\\n| 10. Conclusion | • Recap: the power of generative AI vs. its responsibility <br>• Call to action: experiment, stay ethical, collaborate | 150–200 |\\n\\n### Outline Narrative Flow (How It Will Read)\\n\\n1. **Hook** – A 4‑sentence opener that instantly makes the reader care about generative AI’s relevance.\\n2. **Context** – Briefly lay out the timeline: what generative AI started, why it matters now.\\n3. **Deep Dive** – Thorough section on how the core models work, with diagrams and analogies.\\n4. **Utility Showcase** – Piece of each column: creative, business, science—showing breadth.\\n5. **Pros** – Build positive tone: speed, cost, democratization.\\n6. **Cons** – Balance with honest risks and ethics, peppered with real examples.\\n7. **Practical Playbook** – Equip the reader with a step‑by‑step so they feel ready to go from zero to PoC.\\n8. **Future Vision** – Keep the mood optimistic, painting a picture of upcoming changes.\\n9. **Toolkit** – Provide concrete next‑step resources so the blog is actionable.\\n10. **Close** – Summarize and issue a motivational classic: “Let’s use generative AI responsibly.”\\n\\nFeel free to adjust the word counts or change the emphasis depending on target readers (tech‑savvy vs. senior executives). This outline is sufficiently detailed for you to flesh out into a complete, engaging blog post.',\n",
       " 'content': '# Generative AI – From Groundbreaking Theory to Everyday Impact  \\n\\n---\\n\\n## 1. Introduction  \\n*“What if your computer could write a novel, design a car, or even compose orchestral music? That’s Generative AI.”*  \\n\\nGenerative AI is the class of machine‑learning models that **create** new data—text, images, sound, code, and more—rather than just classifying or predicting it. Over the past decade it has moved from esoteric research to tools that can be dropped into a marketer’s workflow, a healthcare engineer’s lab notebook, or a student’s creative portfolio.  \\n\\nIn this post we’ll trace its evolution from rudimentary statistical tricks to the sophisticated multimodal systems of today, demystify the core tech under the hood, showcase the breadth of real‑world use cases, quantify the benefits, confront the risks, and finally give you a step‑by‑step playbook for bringing generative AI into your own organization.  \\n\\n---\\n\\n## 2. From Concept to Reality  \\n\\n### 2.1 Early Foundations  \\n* **1970s–1980s** – Markov chains, n‑gram language models.  \\n* **1990s** – Probabilistic graphical models, hidden Markov models (HMMs).  \\n\\nThese models build a probability of the next token based on a fixed window of previous tokens; they were fast but shallow.\\n\\n### 2.2 Birth of Generative Models  \\n* **1990s‑2000s** – Autoencoders, Restricted Boltzmann Machines (RBMs).  \\n  * *Autoencoders* compress data to a “latent” space and reconstruct it.  \\n  * *RBMs* explored probabilistic latent variables with energy‑based learning.  \\n\\nBoth laid the groundwork for *distribution learning* – a prerequisite for creation.\\n\\n### 2.3 The Rise of Deep Learning  \\n* **2014** – Goodfellow et\\u202fal. crack the first “black‑box” creation problem with **GANs**, training a generator to mimic real data while a discriminator learns to spot fakes.  \\n* **2014‑2017** – Variational Autoencoders (VAEs) emerge, adding probabilistic sampling to the encoding–decoding pipeline.  \\n* **2018 & beyond** – Transformer language models (BERT, GPT‑2/3/4) revolutionize autoregressive text generation.  \\n\\nBy 2022, the \"ATGPT\" analogy feels apt: *Autoregressive Transformers Generate Purpose‑full Text*—a natural progression from statistical beginnings to deep‑learning mastery.\\n\\n---\\n\\n## 3. How Generative AI Works  \\n\\n### 3.1 Core Technologies  \\n\\n| Model | Core Idea | Training Loop | Key Artifact |\\n|-------|-----------|---------------|--------------|\\n| **GAN** | Adversarial game between Generator & Discriminator | Min‑max loss; back‑prop to both networks | Image or data sample |\\n| **VAE** | Learning a latent distribution via stochastic nodes | Reconstruction loss + KL‑divergence | Probability density |\\n| **Transformer** | Self‑attention, token embeddings | Next‑token prediction (cross‑entropy) | Sequence generator |\\n\\n#### 3.1.1 GANs (Adversarial Training)  \\n*Diagram* (textual):  \\n```\\n┌───────────────┐              ┌───────────────┐\\n│  Generator    │  ⇄ fake data  │  Discriminator │\\n└─────┬─────────┘              └─────┬─────────┘\\n      │ training loss              │ loss\\n      ▼                            ▼\\n   Update G                         Update D\\n```\\n*Latent vector* → G → Fake image → D → Loss → G improves, D improves. The training is a zero‑sum game.\\n\\n#### 3.1.2 VAEs (Probabilistic Sampling)  \\nencoder → μ & σ → reparameterize → z → decoder → reconstruction.  \\nLoss = **Reconstruction Error** + **KL Divergence**.  \\nGreat for *controlled* generation; you can tweak the latent vector to steer output.\\n\\n#### 3.1.3 Transformers (Attention & Autoregression)  \\nTokens → Embedding → Positional Encoding → Stack of *self‑attention* blocks → Predict **next token** (softmax over vocab).  \\nBecause attention lets the model weigh every previous token, Transformers excel at long‑range dependencies—vital for narrative text, code, or articles.\\n\\n### 3.2 Training Data & Computational Demands  \\n\\n1. **Data** – Billion‑word corpora (OpenWebText, Common Crawl) or curated image datasets (ImageNet).  \\n2. **Hardware** – Multi‑GPU (NVIDIA A100), TPUs, or cloud VMs.  \\n3. **Time** – GPT‑4 style models cost **hundreds of thousands of dollars** in raw compute.  \\n4. **Legal** – Data licensing, copyright, and ownership can be a minefield.  \\n\\nLarge‑scale training is a *resource‑heavy* endeavor; however, fine‑tuning and inference APIs give smaller teams access to near‑state‑of‑the‑art models without the upfront cost.\\n\\n---\\n\\n## 4. Applications – The “Why It Matters” Section  \\n\\n| Domain | Use Case | Example Products | Key Metrics |\\n|---------|----------|----------------|-------------|\\n| Creative Arts | **Music composition** | OpenAI Jukebox | 5‑minute tracks generated in seconds |\\n|  | **Visual art** | DALL‑E 3, Midjourney | High‑resolution image generation |\\n| Film & Animation | Procedural storyboards | Runway Gen-2 | 5x faster pre‑visualization |\\n| Business & Productivity | **Content creation** | Jasper.ai, Copy.ai | 2x speed on blog drafts; 30% lower cost |\\n|  | **Code generation** | GitHub Copilot, Tabnine | 50% of code in refactor tasks |\\n| Healthcare & Science | **Molecular design** | Insilico Medicine, Schrödinger AI | 10x faster virtual screening |\\n|  | **Drug discovery** | Atomwise, DeepGenomics | 70% reduction in candidate molecules |\\n| Education & Accessibility | **Tutoring bots** | Otter.ai, Socratic | 20% increase in student engagement |\\n| Social Media & Marketing | **Image & caption** | Canva Magic Write | 15% lift in click‑through rates |\\n\\n**Illustration**:  \\nA marketing agency uses GPT‑4 to produce **50% of the copy** for a quarterly report in just an hour versus a 2‑week effort by writers. A biochemist harnesses a VAE‑based platform to generate **new drug candidates** in minutes, saving a $5\\u202fM research budget.\\n\\n---\\n\\n## 5. Benefits & Advantages  \\n\\n| Benefit | Why It Matters | Example |\\n|---------|----------------|---------|\\n| **Speed & Scale** | Generate content, designs, code in seconds | GPT‑4 drafts legal briefs in minutes |\\n| **Lower Cost** | Reduces labor hours, eliminates tooling overhead | AI‑generated designs cut CAD costs by 40% |\\n| **Democratization of Expertise** | Non‑experts can produce professional‑level output | Small studios beat large agencies in animation |\\n| **Personalization** | Tailored experiences at scale | AI‑curated study plans adapting to a learner’s rhythm |\\n\\nQuantitatively: *“A single GPT‑4 model can draft 50% of the copy in a 100‑page document in an hour.”*  \\nThe democratizing effect spans from entry‑level marketing teams to indie game developers.\\n\\n---\\n\\n## 6. Risks, Ethics & Social Implications  \\n\\n| Risk | Real‑World Instance | Mitigation |\\n|------|---------------------|------------|\\n| **Bias & Fairness** | AI art models reproducing stereotypes in generated portraits | Diverse training sets + bias audits |\\n| **Copyright & Plagiarism** | Jukebox remixing copyrighted tracks without consent | Licensing checks + content filters |\\n| **Deepfakes & Misinformation** | Synth‑deep video spamming election feeds | Watermarking, detection pipelines |\\n| **Environmental Impact** | GPT‑3 training ~ 1.2\\u202fMtCO₂e | Efficient architectures, carbon offset |\\n| **Accountability & Governance** | “Black‑box” decisions in hiring tools | Explainable AI, model cards |\\n\\n**Case Study** – *Picasso-Style Bias*: A generative art app produced artworks with color palettes tied to socio‑demographics, revealing latent biases. This prompted a review of training data sources.  \\n\\nPolicy responses: *EU AI Act*, *US AI‑Risk Management Standards*, *Responsible AI Frameworks* are starting to codify responsible development paths.\\n\\n---\\n\\n## 7. The Business Adoption Playbook  \\n\\n1. **Identify Use\\u202fCase**  \\n   *Define the business problem.*  \\n   *E.g.*, “Reduce content‑creation time for product manuals.”\\n\\n2. **Proof‑of‑Concept (PoC)**  \\n   *Scope data (public corpora + proprietary docs).*  \\n   *Fine‑tune a GPT‑3.5‑like model on 10\\u202fk words.*  \\n   *Measure quality (BLEU, human eval).*\\n\\n3. **Choose Model Strategy**  \\n   *In‑house*: Build & host a small VAE or LSTM.  \\n   *API*: GPT‑4 via OpenAI, Claude 3 via Anthropic.  \\n   *Hybrid*: Fine‑tune on Cloud, run inference locally.\\n\\n4. **Integrate with Workflows**  \\n   *Chatbot interface* → *Content repo* → *Edits → Publish.*  \\n   Use *CI/CD* for model updates.  \\n\\n5. **Upskill & Change Management**  \\n   *Train non‑technical staff on prompt‑engineering.*  \\n   *Create policy for “human‑in‑the‑loop” edits.*\\n\\n6. **Scale & Iterate**  \\n   *Deploy to high‑volume pipelines.*  \\n   *Track KPI uplift (time, cost).*\\n\\n**Value‑Chain Diagram** (text):  \\n```\\nData → Feature Engineering → Model ↔ API ↔ Workflow Tool → Output → Feedback Loop\\n```\\n\\n---\\n\\n## 8. Emerging Trends & the Road Ahead  \\n\\n| Trend | What It Means | Nearby Milestones |\\n|-------|--------------|--------------------|\\n| **Multi‑Modal Models** | Seamless text, image, audio synthesis | Claude 3.5, Gemini, GPT‑5’ish |\\n| **Federated & Edge Generative AI** | On‑device generation, privacy‑preserving | Apple Core ML, Google Edge Networks |\\n| **Self‑Training & Continual Learning** | Models that improve from post‑deployment data | OpenAI’s InstructGPT updates in real time |\\n| **AI‑Designed Hardware** | Chipsets optimized for attention heads & transformer ops | NVIDIA H100, Google TPU‑V4 |\\n| **Human‑In‑The‑Loop (HITL) Frameworks** | Structured workflows for analyst approval | Prompt‑by‑Example + Safety Filters |\\n\\nSpeculation: *Neural‑rendered graphics in VR*—a viewer could walk through a procedurally generated city that adapts to user choices in real time. Governance may evolve into *AI‑generated legislation models* that propose policy drafts.\\n\\n---\\n\\n## 9. Resources & Next Steps  \\n\\n| Category | Recommendation | Why It Matters |\\n|----------|-----------------|----------------|\\n| **Key Reading** | *“Deep Generative Modeling”* (Goodfellow, 2014) | Foundation understanding |\\n| | *“Attention Is All You Need”* (Vaswani et\\u202fal., 2017) | Transformer core paper |\\n| | *“The Climate Impact of Neural Networks”* (Strubell et\\u202fal., 2019) | Ethics & sustainability |\\n| **Open‑Source Tools** | **Hugging\\u202fFace Transformers** – APIs, model hub | Fine‑tune & deploy |\\n| | **Diffusers** – Stable Diffusion pipelines | Image generation |\\n| | **LangChain** – Orchestration of LLMs | Building complex apps |\\n| **Learning Paths** | Coursera: *Generative AI: The Future of Creativity* | Structured curriculum |\\n| | Fast.ai: *Practical Deep Learning for Coders* | Hands‑on |\\n| **Communities & Conferences** | AI\\u202fReview, NeurIPS, ICML, ML Ops Summit | Networking & updates |\\n| **Action Plan** | 1. Start with GPT‑4 API for prototype. 2. Gather internal data. 3. Iterate prompts. 4. Scale via fine‑tune. | Real‑world roadmap |\\n\\n---\\n\\n## 10. Conclusion  \\n\\nGenerative AI has evolved from simple statistical “guessers” to sophisticated, multimodal creators that can produce code, music, images, and nuanced prose at industry‑scale speed and cost. The technology promises democratization, hyper‑personalization, and unprecedented efficiency—but it also carries serious ethical, legal, and environmental responsibilities.  \\n\\nIf you’re ready to experiment, keep these principles in mind: *start small, assess impact, involve human judgment, and stay transparent.* Let’s harness generative AI responsibly and build a future where imagination is no longer constrained by human limitations.  \\n\\n*Happy creating!*',\n",
       " 'blog_score': '**Overall rating: 8\\u202f/\\u202f10**\\n\\n---\\n\\n## What the post nails\\n\\n| Dimension | Strengths |\\n|-----------|----------|\\n| **Scope coverage** | Every outline section appears in the draft, from evolution to use‑cases to a playbook and future outlook. |\\n| **Structure & flow** | The “outline narrative flow” is preserved (hook → context → deep dive → utility → pros/cons → playbook → future.) Sections are clearly headed and organized chronologically. |\\n| **Depth of technical detail** | Core models (GAN, VAE, Transformer) are explained with as much clarity as a non‑expert can understand, and key trade‑offs are highlighted. |\\n| **Real‑world bearings** | You tie the tech to concrete examples (Jukebox, DALL‑E, GitHub Copilot, drug‑discovery ML) and deliver metrics that illustrate value. |\\n| **Risk awareness** | Ethical concerns are addressed with case studies and references to policy initiatives (EU AI Act, US standards). |\\n| **Actionability** | The playbook section gives a step‑by‑step path and the “Resources & Next Steps” rack is a handy plug‑and‑play list. |\\n\\n---\\n\\n## Where the post could be tighter\\n\\n| Issue | Suggested fix |\\n|-------|----------------|\\n| **Word‑count / pacing** | The total word count is ~5‑6\\u202fk; the outline targeted 4\\u202fk–5\\u202fk. Condensing some sections (e.g., cutting a few bullet points in *Benefits* or trimming the “Early Foundations” notes) would keep the reader’s attention sweet‑spot. |\\n| **Visual aids** | The outline promised a GAN diagram and a value‑chain diagram. Embedding (or at least describing) those visuals in the text would improve comprehension and break up the prose. |\\n| **Bullet‑list density** | Some sections (e.g., *Emerging Trends*) are still paragraph‑heavy. Convert key bullet points into concise lists or tables; preserve the matrix in *Applications* but make the table even slimmer. |\\n| **Consistent terminology** | At a few places “transformer” vs. “attention‑based language model” is swapped; keep one phrasing. |\\n| **Call‑to‑action** | The final CTA could be stronger. Instead of “Let’s experiment,” choose an immediate next step (e.g., “Try GPT‑4 through the OpenAI playground today to see what a single prompt can produce.”). |\\n| **Linking back to the intro** | The hook mentions novel writing, car design, music composition. Make a short pivot from the intro to the mixed‑scenario uses early (or at the *Why It Matters* section). |\\n\\n---\\n\\n## Minor polishing checks\\n\\n1. **Grammar & style** – Minor typos (“in an hour.” vs “in an hour”) and contractions are fine for a blog tone but watch for consistency.  \\n2. **Citation style** – Reference the papers explicitly (e.g., *Goodfellow et\\u202fal., 2014* instead of “Goodfellow et\\u202fal.\\u202f2014”) for a more scholarly touch.  \\n3. **Accessibility** – Ensure images/diagrams have alt‑text descriptions and that bullet lists are screen‑reader friendly.  \\n\\n---\\n\\n## Suggested next steps\\n\\n1. **Trim and reorder** | Aim for ~4\\u202fk words by condensing the “Benefits & Advantages” and the “Emerging Trends” sections.  \\n2. **Add visuals** | Even a simple SVG GAN diagram and a flowchart of the playbook would add huge value.  \\n3. **Inline prompts** | In the PoC section, provide a short sample prompt that a non‑techie could paste into the OpenAI playground to see an output.  \\n4. **Proofreading** | Run through a quick style‑guide check (sentence length, passive voice, etc.).  \\n\\n---\\n\\n### Bottom line\\n\\nYour blog is **well‑structured, comprehensive, and readable**. Minor tightening and the injection of a few visuals would elevate the piece from solid to stellar. Keep iterating and you’ll hit that 10‑point mark in no time!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\"title\" : \"Generative AI\"}\n",
    "\n",
    "final_state = workflow.invoke(initial_state)\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "497c2ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Blog Outline  \n",
      "**Title:** *Generative AI – From Groundbreaking Theory to Everyday Impact*\n",
      "\n",
      "| Section | Sub‑sections | Key Talking Points | Suggested Word Count |\n",
      "|---------|--------------|--------------------|----------------------|\n",
      "| 1. Introduction |  | • Hook: “What if your computer could write a novel, design a car, or even compose music? That’s Generative AI.” <br>• Define the scope of the blog: explaining what generative AI is, its evolution, applications, challenges, and the road ahead. <br>• Preview of sections. | 150–200 |\n",
      "| 2. From Concept to Reality | 2.1 Early Foundations <br>2.2 Birth of Generative Models <br>2.3 The Rise of Deep Learning | • Informal “ATGPT” analogy: earliest statistical models → first neural nets → modern deep learning <br>• 1990s: Markov chains, n‑gram models. <br>• 2000‑2010: Autoencoders, Restricted Boltzmann Machines. <br>• 2014‑present: Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs); 2018‑2022: Transformer‑based language models (GPT‑3, GPT‑4). | 500–600 |\n",
      "| 3. How Generative AI Works | 3.1 Core Technologies <br>3.1.1 GANs (adversarial training) <br>3.1.2 VAEs (probabilistic sampling) <br>3.1.3 Transformers (attention & autoregression) <br>3.2 Training Data & Computational Demands | • Diagram of GAN: generator vs. discriminator <br>• Explain latent space, reparameterization trick <br>• Show how Transformers predict next token and generate coherent text <br>• Highlight GPU/TPU spin‑up, cloud APIs, data‑ownership issues | 700–800 |\n",
      "| 4. Applications – The “Why It Matters” Section | 4.1 Creative Arts & Design <br>4.1.1 Music & Visual Arts <br>4.1.2 Film & Animation <br>4.2 Business & Productivity <br>4.2.1 Content Creation & Copywriting <br>4.2.2 Code Generation & Automation <br>4.3 Healthcare & Science <br>4.3.1 Molecular Design <br>4.3.2 Drug Discovery <br>4.4 Education & Accessibility <br>4.5 Social Media & Marketing | • Use bullet‑style real‑world examples: OpenAI’s DALL‑E, Jukebox; GitHub Copilot, LangChain <br>• Cite key metrics (e.g., time saved, accuracy improvements) <br>• Discuss augmentation vs. replacement on the workforce | 1200–1400 |\n",
      "| 5. Benefits & Advantages | 5.1 Speed & Scale <br>5.2 Lower Cost <br>5.3 Democratization of Expertise <br>5.4 Personalization & Customization | • Quantify: “A single GPT‑4 model can draft 50% of the copy in a 100‑page document in an hour.” <br>• Illustrate democratization: small teams now producing on‑par marketing copy vs. agencies. | 400–500 |\n",
      "| 6. Risks, Ethics & Social Implications | 6.1 Bias & Fairness <br>6.2 Copyright & Plagiarism <br>6.3 Deepfakes & Misinformation <br>6.4 Environmental Impact (energy consumption) <br>6.5 Accountability & Governance | • Real case studies: Picasso style AI bias, AI‑generated fake news <br>• Highlight regulatory responses (EU AI Act, US Standards). | 900–1000 |\n",
      "| 7. The Business Adoption Playbook | 7.1 Identifying Use‑Cases <br>7.2 PoC to Production <br>7.3 Choosing the Right Model (in‑house vs. API) <br>7.4 Integration with Existing Workflows <br>7.5 Upskilling & Workforce Considerations | • Use “Value‑Chain” diagram; Example: Content marketing team + GPT‑4. <br>• Step‑by‑step guide for building a pilot (define problem → get data → fine‑tune). | 800–950 |\n",
      "| 8. Emerging Trends & the Road Ahead | 8.1 Multi‑Modal Models (Text+Image+Audio) <br>8.2 Federated & Edge Generative AI <br>8.3 Self‑Training & Continual Learning <br>8.4 AI‑Generated Hardware & Architectures <br>8.5 Human‑In‑The‑Loop (HITL) frameworks | • Mention Claude 3.5, Meta’s Llama‑3, Google Gemini <br>• Speculate on breakthroughs: “Neural‑rendered graphics in VR” <br>• Future of governance: AI‑generated policy documents. | 600–700 |\n",
      "| 9. Resources & Next Steps | 9.1 Key Reading (papers & books) <br>9.2 Open‑Source Tools & Libraries (Hugging Face, Diffusers) <br>9.3 Learning Paths (Coursera, Fast.ai) <br>9.4 Communities & Conferences | • Provide curated links. <br>• Recommendation for practitioners: “Start with GPT‑4 via OpenAI API, then build your own fine‑tuned model.” | 300–400 |\n",
      "| 10. Conclusion | • Recap: the power of generative AI vs. its responsibility <br>• Call to action: experiment, stay ethical, collaborate | 150–200 |\n",
      "\n",
      "### Outline Narrative Flow (How It Will Read)\n",
      "\n",
      "1. **Hook** – A 4‑sentence opener that instantly makes the reader care about generative AI’s relevance.\n",
      "2. **Context** – Briefly lay out the timeline: what generative AI started, why it matters now.\n",
      "3. **Deep Dive** – Thorough section on how the core models work, with diagrams and analogies.\n",
      "4. **Utility Showcase** – Piece of each column: creative, business, science—showing breadth.\n",
      "5. **Pros** – Build positive tone: speed, cost, democratization.\n",
      "6. **Cons** – Balance with honest risks and ethics, peppered with real examples.\n",
      "7. **Practical Playbook** – Equip the reader with a step‑by‑step so they feel ready to go from zero to PoC.\n",
      "8. **Future Vision** – Keep the mood optimistic, painting a picture of upcoming changes.\n",
      "9. **Toolkit** – Provide concrete next‑step resources so the blog is actionable.\n",
      "10. **Close** – Summarize and issue a motivational classic: “Let’s use generative AI responsibly.”\n",
      "\n",
      "Feel free to adjust the word counts or change the emphasis depending on target readers (tech‑savvy vs. senior executives). This outline is sufficiently detailed for you to flesh out into a complete, engaging blog post.\n"
     ]
    }
   ],
   "source": [
    "print(final_state['outline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d6f69ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Generative AI – From Groundbreaking Theory to Everyday Impact  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. Introduction  \n",
      "*“What if your computer could write a novel, design a car, or even compose orchestral music? That’s Generative AI.”*  \n",
      "\n",
      "Generative AI is the class of machine‑learning models that **create** new data—text, images, sound, code, and more—rather than just classifying or predicting it. Over the past decade it has moved from esoteric research to tools that can be dropped into a marketer’s workflow, a healthcare engineer’s lab notebook, or a student’s creative portfolio.  \n",
      "\n",
      "In this post we’ll trace its evolution from rudimentary statistical tricks to the sophisticated multimodal systems of today, demystify the core tech under the hood, showcase the breadth of real‑world use cases, quantify the benefits, confront the risks, and finally give you a step‑by‑step playbook for bringing generative AI into your own organization.  \n",
      "\n",
      "---\n",
      "\n",
      "## 2. From Concept to Reality  \n",
      "\n",
      "### 2.1 Early Foundations  \n",
      "* **1970s–1980s** – Markov chains, n‑gram language models.  \n",
      "* **1990s** – Probabilistic graphical models, hidden Markov models (HMMs).  \n",
      "\n",
      "These models build a probability of the next token based on a fixed window of previous tokens; they were fast but shallow.\n",
      "\n",
      "### 2.2 Birth of Generative Models  \n",
      "* **1990s‑2000s** – Autoencoders, Restricted Boltzmann Machines (RBMs).  \n",
      "  * *Autoencoders* compress data to a “latent” space and reconstruct it.  \n",
      "  * *RBMs* explored probabilistic latent variables with energy‑based learning.  \n",
      "\n",
      "Both laid the groundwork for *distribution learning* – a prerequisite for creation.\n",
      "\n",
      "### 2.3 The Rise of Deep Learning  \n",
      "* **2014** – Goodfellow et al. crack the first “black‑box” creation problem with **GANs**, training a generator to mimic real data while a discriminator learns to spot fakes.  \n",
      "* **2014‑2017** – Variational Autoencoders (VAEs) emerge, adding probabilistic sampling to the encoding–decoding pipeline.  \n",
      "* **2018 & beyond** – Transformer language models (BERT, GPT‑2/3/4) revolutionize autoregressive text generation.  \n",
      "\n",
      "By 2022, the \"ATGPT\" analogy feels apt: *Autoregressive Transformers Generate Purpose‑full Text*—a natural progression from statistical beginnings to deep‑learning mastery.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. How Generative AI Works  \n",
      "\n",
      "### 3.1 Core Technologies  \n",
      "\n",
      "| Model | Core Idea | Training Loop | Key Artifact |\n",
      "|-------|-----------|---------------|--------------|\n",
      "| **GAN** | Adversarial game between Generator & Discriminator | Min‑max loss; back‑prop to both networks | Image or data sample |\n",
      "| **VAE** | Learning a latent distribution via stochastic nodes | Reconstruction loss + KL‑divergence | Probability density |\n",
      "| **Transformer** | Self‑attention, token embeddings | Next‑token prediction (cross‑entropy) | Sequence generator |\n",
      "\n",
      "#### 3.1.1 GANs (Adversarial Training)  \n",
      "*Diagram* (textual):  \n",
      "```\n",
      "┌───────────────┐              ┌───────────────┐\n",
      "│  Generator    │  ⇄ fake data  │  Discriminator │\n",
      "└─────┬─────────┘              └─────┬─────────┘\n",
      "      │ training loss              │ loss\n",
      "      ▼                            ▼\n",
      "   Update G                         Update D\n",
      "```\n",
      "*Latent vector* → G → Fake image → D → Loss → G improves, D improves. The training is a zero‑sum game.\n",
      "\n",
      "#### 3.1.2 VAEs (Probabilistic Sampling)  \n",
      "encoder → μ & σ → reparameterize → z → decoder → reconstruction.  \n",
      "Loss = **Reconstruction Error** + **KL Divergence**.  \n",
      "Great for *controlled* generation; you can tweak the latent vector to steer output.\n",
      "\n",
      "#### 3.1.3 Transformers (Attention & Autoregression)  \n",
      "Tokens → Embedding → Positional Encoding → Stack of *self‑attention* blocks → Predict **next token** (softmax over vocab).  \n",
      "Because attention lets the model weigh every previous token, Transformers excel at long‑range dependencies—vital for narrative text, code, or articles.\n",
      "\n",
      "### 3.2 Training Data & Computational Demands  \n",
      "\n",
      "1. **Data** – Billion‑word corpora (OpenWebText, Common Crawl) or curated image datasets (ImageNet).  \n",
      "2. **Hardware** – Multi‑GPU (NVIDIA A100), TPUs, or cloud VMs.  \n",
      "3. **Time** – GPT‑4 style models cost **hundreds of thousands of dollars** in raw compute.  \n",
      "4. **Legal** – Data licensing, copyright, and ownership can be a minefield.  \n",
      "\n",
      "Large‑scale training is a *resource‑heavy* endeavor; however, fine‑tuning and inference APIs give smaller teams access to near‑state‑of‑the‑art models without the upfront cost.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Applications – The “Why It Matters” Section  \n",
      "\n",
      "| Domain | Use Case | Example Products | Key Metrics |\n",
      "|---------|----------|----------------|-------------|\n",
      "| Creative Arts | **Music composition** | OpenAI Jukebox | 5‑minute tracks generated in seconds |\n",
      "|  | **Visual art** | DALL‑E 3, Midjourney | High‑resolution image generation |\n",
      "| Film & Animation | Procedural storyboards | Runway Gen-2 | 5x faster pre‑visualization |\n",
      "| Business & Productivity | **Content creation** | Jasper.ai, Copy.ai | 2x speed on blog drafts; 30% lower cost |\n",
      "|  | **Code generation** | GitHub Copilot, Tabnine | 50% of code in refactor tasks |\n",
      "| Healthcare & Science | **Molecular design** | Insilico Medicine, Schrödinger AI | 10x faster virtual screening |\n",
      "|  | **Drug discovery** | Atomwise, DeepGenomics | 70% reduction in candidate molecules |\n",
      "| Education & Accessibility | **Tutoring bots** | Otter.ai, Socratic | 20% increase in student engagement |\n",
      "| Social Media & Marketing | **Image & caption** | Canva Magic Write | 15% lift in click‑through rates |\n",
      "\n",
      "**Illustration**:  \n",
      "A marketing agency uses GPT‑4 to produce **50% of the copy** for a quarterly report in just an hour versus a 2‑week effort by writers. A biochemist harnesses a VAE‑based platform to generate **new drug candidates** in minutes, saving a $5 M research budget.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Benefits & Advantages  \n",
      "\n",
      "| Benefit | Why It Matters | Example |\n",
      "|---------|----------------|---------|\n",
      "| **Speed & Scale** | Generate content, designs, code in seconds | GPT‑4 drafts legal briefs in minutes |\n",
      "| **Lower Cost** | Reduces labor hours, eliminates tooling overhead | AI‑generated designs cut CAD costs by 40% |\n",
      "| **Democratization of Expertise** | Non‑experts can produce professional‑level output | Small studios beat large agencies in animation |\n",
      "| **Personalization** | Tailored experiences at scale | AI‑curated study plans adapting to a learner’s rhythm |\n",
      "\n",
      "Quantitatively: *“A single GPT‑4 model can draft 50% of the copy in a 100‑page document in an hour.”*  \n",
      "The democratizing effect spans from entry‑level marketing teams to indie game developers.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Risks, Ethics & Social Implications  \n",
      "\n",
      "| Risk | Real‑World Instance | Mitigation |\n",
      "|------|---------------------|------------|\n",
      "| **Bias & Fairness** | AI art models reproducing stereotypes in generated portraits | Diverse training sets + bias audits |\n",
      "| **Copyright & Plagiarism** | Jukebox remixing copyrighted tracks without consent | Licensing checks + content filters |\n",
      "| **Deepfakes & Misinformation** | Synth‑deep video spamming election feeds | Watermarking, detection pipelines |\n",
      "| **Environmental Impact** | GPT‑3 training ~ 1.2 MtCO₂e | Efficient architectures, carbon offset |\n",
      "| **Accountability & Governance** | “Black‑box” decisions in hiring tools | Explainable AI, model cards |\n",
      "\n",
      "**Case Study** – *Picasso-Style Bias*: A generative art app produced artworks with color palettes tied to socio‑demographics, revealing latent biases. This prompted a review of training data sources.  \n",
      "\n",
      "Policy responses: *EU AI Act*, *US AI‑Risk Management Standards*, *Responsible AI Frameworks* are starting to codify responsible development paths.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. The Business Adoption Playbook  \n",
      "\n",
      "1. **Identify Use Case**  \n",
      "   *Define the business problem.*  \n",
      "   *E.g.*, “Reduce content‑creation time for product manuals.”\n",
      "\n",
      "2. **Proof‑of‑Concept (PoC)**  \n",
      "   *Scope data (public corpora + proprietary docs).*  \n",
      "   *Fine‑tune a GPT‑3.5‑like model on 10 k words.*  \n",
      "   *Measure quality (BLEU, human eval).*\n",
      "\n",
      "3. **Choose Model Strategy**  \n",
      "   *In‑house*: Build & host a small VAE or LSTM.  \n",
      "   *API*: GPT‑4 via OpenAI, Claude 3 via Anthropic.  \n",
      "   *Hybrid*: Fine‑tune on Cloud, run inference locally.\n",
      "\n",
      "4. **Integrate with Workflows**  \n",
      "   *Chatbot interface* → *Content repo* → *Edits → Publish.*  \n",
      "   Use *CI/CD* for model updates.  \n",
      "\n",
      "5. **Upskill & Change Management**  \n",
      "   *Train non‑technical staff on prompt‑engineering.*  \n",
      "   *Create policy for “human‑in‑the‑loop” edits.*\n",
      "\n",
      "6. **Scale & Iterate**  \n",
      "   *Deploy to high‑volume pipelines.*  \n",
      "   *Track KPI uplift (time, cost).*\n",
      "\n",
      "**Value‑Chain Diagram** (text):  \n",
      "```\n",
      "Data → Feature Engineering → Model ↔ API ↔ Workflow Tool → Output → Feedback Loop\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Emerging Trends & the Road Ahead  \n",
      "\n",
      "| Trend | What It Means | Nearby Milestones |\n",
      "|-------|--------------|--------------------|\n",
      "| **Multi‑Modal Models** | Seamless text, image, audio synthesis | Claude 3.5, Gemini, GPT‑5’ish |\n",
      "| **Federated & Edge Generative AI** | On‑device generation, privacy‑preserving | Apple Core ML, Google Edge Networks |\n",
      "| **Self‑Training & Continual Learning** | Models that improve from post‑deployment data | OpenAI’s InstructGPT updates in real time |\n",
      "| **AI‑Designed Hardware** | Chipsets optimized for attention heads & transformer ops | NVIDIA H100, Google TPU‑V4 |\n",
      "| **Human‑In‑The‑Loop (HITL) Frameworks** | Structured workflows for analyst approval | Prompt‑by‑Example + Safety Filters |\n",
      "\n",
      "Speculation: *Neural‑rendered graphics in VR*—a viewer could walk through a procedurally generated city that adapts to user choices in real time. Governance may evolve into *AI‑generated legislation models* that propose policy drafts.\n",
      "\n",
      "---\n",
      "\n",
      "## 9. Resources & Next Steps  \n",
      "\n",
      "| Category | Recommendation | Why It Matters |\n",
      "|----------|-----------------|----------------|\n",
      "| **Key Reading** | *“Deep Generative Modeling”* (Goodfellow, 2014) | Foundation understanding |\n",
      "| | *“Attention Is All You Need”* (Vaswani et al., 2017) | Transformer core paper |\n",
      "| | *“The Climate Impact of Neural Networks”* (Strubell et al., 2019) | Ethics & sustainability |\n",
      "| **Open‑Source Tools** | **Hugging Face Transformers** – APIs, model hub | Fine‑tune & deploy |\n",
      "| | **Diffusers** – Stable Diffusion pipelines | Image generation |\n",
      "| | **LangChain** – Orchestration of LLMs | Building complex apps |\n",
      "| **Learning Paths** | Coursera: *Generative AI: The Future of Creativity* | Structured curriculum |\n",
      "| | Fast.ai: *Practical Deep Learning for Coders* | Hands‑on |\n",
      "| **Communities & Conferences** | AI Review, NeurIPS, ICML, ML Ops Summit | Networking & updates |\n",
      "| **Action Plan** | 1. Start with GPT‑4 API for prototype. 2. Gather internal data. 3. Iterate prompts. 4. Scale via fine‑tune. | Real‑world roadmap |\n",
      "\n",
      "---\n",
      "\n",
      "## 10. Conclusion  \n",
      "\n",
      "Generative AI has evolved from simple statistical “guessers” to sophisticated, multimodal creators that can produce code, music, images, and nuanced prose at industry‑scale speed and cost. The technology promises democratization, hyper‑personalization, and unprecedented efficiency—but it also carries serious ethical, legal, and environmental responsibilities.  \n",
      "\n",
      "If you’re ready to experiment, keep these principles in mind: *start small, assess impact, involve human judgment, and stay transparent.* Let’s harness generative AI responsibly and build a future where imagination is no longer constrained by human limitations.  \n",
      "\n",
      "*Happy creating!*\n"
     ]
    }
   ],
   "source": [
    "print(final_state['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b727b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Overall rating: 8 / 10**\n",
      "\n",
      "---\n",
      "\n",
      "## What the post nails\n",
      "\n",
      "| Dimension | Strengths |\n",
      "|-----------|----------|\n",
      "| **Scope coverage** | Every outline section appears in the draft, from evolution to use‑cases to a playbook and future outlook. |\n",
      "| **Structure & flow** | The “outline narrative flow” is preserved (hook → context → deep dive → utility → pros/cons → playbook → future.) Sections are clearly headed and organized chronologically. |\n",
      "| **Depth of technical detail** | Core models (GAN, VAE, Transformer) are explained with as much clarity as a non‑expert can understand, and key trade‑offs are highlighted. |\n",
      "| **Real‑world bearings** | You tie the tech to concrete examples (Jukebox, DALL‑E, GitHub Copilot, drug‑discovery ML) and deliver metrics that illustrate value. |\n",
      "| **Risk awareness** | Ethical concerns are addressed with case studies and references to policy initiatives (EU AI Act, US standards). |\n",
      "| **Actionability** | The playbook section gives a step‑by‑step path and the “Resources & Next Steps” rack is a handy plug‑and‑play list. |\n",
      "\n",
      "---\n",
      "\n",
      "## Where the post could be tighter\n",
      "\n",
      "| Issue | Suggested fix |\n",
      "|-------|----------------|\n",
      "| **Word‑count / pacing** | The total word count is ~5‑6 k; the outline targeted 4 k–5 k. Condensing some sections (e.g., cutting a few bullet points in *Benefits* or trimming the “Early Foundations” notes) would keep the reader’s attention sweet‑spot. |\n",
      "| **Visual aids** | The outline promised a GAN diagram and a value‑chain diagram. Embedding (or at least describing) those visuals in the text would improve comprehension and break up the prose. |\n",
      "| **Bullet‑list density** | Some sections (e.g., *Emerging Trends*) are still paragraph‑heavy. Convert key bullet points into concise lists or tables; preserve the matrix in *Applications* but make the table even slimmer. |\n",
      "| **Consistent terminology** | At a few places “transformer” vs. “attention‑based language model” is swapped; keep one phrasing. |\n",
      "| **Call‑to‑action** | The final CTA could be stronger. Instead of “Let’s experiment,” choose an immediate next step (e.g., “Try GPT‑4 through the OpenAI playground today to see what a single prompt can produce.”). |\n",
      "| **Linking back to the intro** | The hook mentions novel writing, car design, music composition. Make a short pivot from the intro to the mixed‑scenario uses early (or at the *Why It Matters* section). |\n",
      "\n",
      "---\n",
      "\n",
      "## Minor polishing checks\n",
      "\n",
      "1. **Grammar & style** – Minor typos (“in an hour.” vs “in an hour”) and contractions are fine for a blog tone but watch for consistency.  \n",
      "2. **Citation style** – Reference the papers explicitly (e.g., *Goodfellow et al., 2014* instead of “Goodfellow et al. 2014”) for a more scholarly touch.  \n",
      "3. **Accessibility** – Ensure images/diagrams have alt‑text descriptions and that bullet lists are screen‑reader friendly.  \n",
      "\n",
      "---\n",
      "\n",
      "## Suggested next steps\n",
      "\n",
      "1. **Trim and reorder** | Aim for ~4 k words by condensing the “Benefits & Advantages” and the “Emerging Trends” sections.  \n",
      "2. **Add visuals** | Even a simple SVG GAN diagram and a flowchart of the playbook would add huge value.  \n",
      "3. **Inline prompts** | In the PoC section, provide a short sample prompt that a non‑techie could paste into the OpenAI playground to see an output.  \n",
      "4. **Proofreading** | Run through a quick style‑guide check (sentence length, passive voice, etc.).  \n",
      "\n",
      "---\n",
      "\n",
      "### Bottom line\n",
      "\n",
      "Your blog is **well‑structured, comprehensive, and readable**. Minor tightening and the injection of a few visuals would elevate the piece from solid to stellar. Keep iterating and you’ll hit that 10‑point mark in no time!\n"
     ]
    }
   ],
   "source": [
    "print(final_state['blog_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
